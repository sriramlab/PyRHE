{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 909,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from bed_reader import open_bed, sample_file\n",
    "\n",
    "class Data:\n",
    "    def __init__(self):\n",
    "        self.gen = None\n",
    "        self.index = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 910,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulator(allgen, sigma):\n",
    "    '''\n",
    "    Simulate phenotype y from X and sigmas\n",
    "    '''\n",
    "    X = allgen[0].gen\n",
    "    N = X.shape[0]\n",
    "    M = X.shape[1]\n",
    "    y = np.zeros((N,1))\n",
    "    sigma_epsilon=1 - sigma # environmental effect sizes\n",
    "    betas = np.random.randn(M,1)*np.sqrt(sigma) # additive SNP effect sizes\n",
    "    y += X@betas/np.sqrt(M) # weight \n",
    "    #print(f'sigma_epislon={sigma_epsilon}') \n",
    "    y += np.random.randn(N,1)*np.sqrt(sigma_epsilon) # add the bias\n",
    "    return y, betas\n",
    "\n",
    "def simulator_multi_bin(allgen, sigma_list):\n",
    "    '''\n",
    "    Simulate phenotype y from X and sigma_list\n",
    "    '''\n",
    "    N_indv = allgen[0].gen.shape[0]\n",
    "    h = 1 - sum(sigma_list) # residual covariance\n",
    "\n",
    "    sigma_epsilon = np.random.multivariate_normal([0] * N_indv, np.diag(np.full(N_indv, h)))\n",
    "\n",
    "    sigma_epsilon = np.array(sigma_epsilon).reshape((len(sigma_epsilon), 1))\n",
    "\n",
    "    y = np.zeros((N_indv,1))\n",
    "\n",
    "    betas = []\n",
    "\n",
    "    for i, data in enumerate(allgen):\n",
    "        X = data.gen\n",
    "        M = X.shape[1]\n",
    "        sigma = sigma_list[i]\n",
    "        beta = np.random.multivariate_normal([0] * M, np.diag(np.full(M, sigma / M)))\n",
    "        beta = np.array(beta).reshape((len(beta), 1))\n",
    "        betas.append(beta)\n",
    "        y += X@beta\n",
    "    \n",
    "    y +=  sigma_epsilon \n",
    "\n",
    "    return y, betas\n",
    "\n",
    "def solve_linear_equation(X, y):\n",
    "    '''\n",
    "    Solve least square\n",
    "    '''\n",
    "    sigma = np.linalg.lstsq(X, y, rcond=None)[0]\n",
    "    return sigma\n",
    "\n",
    "\n",
    "def solve_linear_qr(X, y):\n",
    "    '''\n",
    "    Solve least square using QR decomposition\n",
    "    '''\n",
    "    Q, R = scipy.linalg.qr(X)\n",
    "    sigma = scipy.linalg.solve_triangular(R, np.dot(Q.T, y))\n",
    "    return sigma\n",
    "\n",
    "def RHE_multi_bin(allgen,y,num_random_vect=10,seed=1,verbose=False):\n",
    "    '''\n",
    "    RHE estimation for multi bins\n",
    "    '''\n",
    "\n",
    "    K = len(allgen)\n",
    "\n",
    "    T = np.zeros((K+1, K+1))\n",
    "\n",
    "    q = np.zeros((K+1, 1))\n",
    "\n",
    "    for i, data_1 in enumerate(allgen):\n",
    "        for j, data_2 in enumerate(allgen):\n",
    "            gen_1 = data_1.gen\n",
    "            gen_2 = data_2.gen\n",
    "            N1 = gen_1.shape[0]\n",
    "            N2 = gen_2.shape[0]\n",
    "            assert N1 == N2\n",
    "            M1 = gen_1.shape[1]\n",
    "            M2 = gen_1.shape[1]\n",
    "            Xi_1 = gen_1.copy()/np.sqrt(M1)\n",
    "            Xi_2 = gen_2.copy()/np.sqrt(M2)\n",
    "            for _ in range(num_random_vect):\n",
    "                # Generate random vector to estimate trace\n",
    "                rand_vector = np.random.randn(N1,1)\n",
    "                T[i,j] += rand_vector.T@Xi_1@Xi_1.T@Xi_2@Xi_2.T@rand_vector/num_random_vect\n",
    "    \n",
    "    for i, data in enumerate(allgen):\n",
    "        X = data.gen\n",
    "        M = X.shape[1]\n",
    "        Xi = X.copy()/np.sqrt(M)\n",
    "        T[i, K] = np.trace(Xi@Xi.T)\n",
    "        T[K, i] = np.trace(Xi@Xi.T)\n",
    "        q[i] = y.T@Xi@Xi.T@y\n",
    "\n",
    "    T[K, K] = allgen[0].gen.shape[0]\n",
    "\n",
    "    q[K] = y.T@y\n",
    "\n",
    "\n",
    "    if verbose:\n",
    "        print(T)\n",
    "    sigma_est = solve_linear_qr(T,q)\n",
    "    return sigma_est"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 911,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulate_geno_from_random(p_j):\n",
    "    rval = np.random.random()\n",
    "    dist_pj = [(1-p_j)*(1-p_j), 2*p_j*(1-p_j), p_j*p_j]\n",
    "    \n",
    "    if rval < dist_pj[0]:\n",
    "        return 0\n",
    "    elif rval >= dist_pj[0] and rval < (dist_pj[0] + dist_pj[1]):\n",
    "        return 1\n",
    "    else:\n",
    "        return 2\n",
    "\n",
    "\n",
    "def impute_geno(X):\n",
    "    N = X.shape[0]\n",
    "    M = X.shape[1]\n",
    "    X_imp = X.copy()\n",
    "\n",
    "    for m in range(M):\n",
    "        \n",
    "        observed_sum = 0\n",
    "        observed_ct = 0\n",
    "        for n in range(N):\n",
    "            if not np.isnan(X[n, m]):\n",
    "                observed_ct += 1\n",
    "                observed_sum += X[n, m]\n",
    "        \n",
    "        observed_sum = (observed_sum  / observed_ct)* 0.5\n",
    "\n",
    "        for j in range(N):\n",
    "            if np.isnan(X[j,m]):\n",
    "                X_imp[j, m] = simulate_geno_from_random(observed_sum)\n",
    "                \n",
    "    # standardize\n",
    "    X_imp = (X_imp-np.mean(X_imp, axis=0))/np.std(X_imp, axis=0)\n",
    "\n",
    "    return X_imp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 912,
   "metadata": {},
   "outputs": [],
   "source": [
    "geno_path=\"/Users/nijiayi/RHE_project/data/test2/actual_geno_1.bed\"\n",
    "bed = open_bed(geno_path)\n",
    "X = bed.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 913,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_imp = impute_geno(X)\n",
    "Nindv = X_imp.shape[0]\n",
    "Nsnp = X_imp.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 914,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulate annotation file\n",
    "Nbin = 8\n",
    "\n",
    "import random\n",
    "\n",
    "def create_annot_file(Nsnp, Nbin, filename):\n",
    "    with open(filename, 'w') as f:\n",
    "        for _ in range(Nsnp):\n",
    "            row = [0] * Nbin\n",
    "            random_col = random.randint(0, Nbin - 1)\n",
    "            row[random_col] = 1\n",
    "            f.write(' '.join(str(val) for val in row) + '\\n')\n",
    "\n",
    "filename = '/Users/nijiayi/RHE_project/data/test2/annot.txt'\n",
    "create_annot_file(Nsnp, Nbin, filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 915,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of SNPs per block: 996\n",
      "134 SNPs in 0 -th bin\n",
      "120 SNPs in 1 -th bin\n",
      "119 SNPs in 2 -th bin\n",
      "127 SNPs in 3 -th bin\n",
      "123 SNPs in 4 -th bin\n",
      "134 SNPs in 5 -th bin\n",
      "105 SNPs in 6 -th bin\n",
      "134 SNPs in 7 -th bin\n"
     ]
    }
   ],
   "source": [
    "from RHE.util.file_processing import read_annot\n",
    "\n",
    "filename = '/Users/nijiayi/RHE_project/data/test2/annot.txt'\n",
    "annot_matrix, jack_bin = read_annot(filename, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 916,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bin_to_snp(annot_matrix_chunk): \n",
    "    bin_to_snp_indices = []\n",
    "\n",
    "    for bin_index in range(annot_matrix_chunk.shape[1]):\n",
    "        snp_indices = np.nonzero(annot_matrix_chunk[:, bin_index])[0]\n",
    "        bin_to_snp_indices.append(snp_indices.tolist())\n",
    "\n",
    "    return bin_to_snp_indices\n",
    "\n",
    "bin_to_snp_map = bin_to_snp(annot_matrix)\n",
    "\n",
    "def create_allgen(bin_to_snp_map, X):\n",
    "    allgen = [Data() for _ in range(len(bin_to_snp_map))]\n",
    "\n",
    "    for i, data in enumerate(allgen):\n",
    "        data.index = len(bin_to_snp_map[i])\n",
    "        data.gen = X[:, bin_to_snp_map[i]]\n",
    "\n",
    "    return allgen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 917,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual sigmas are: [0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1]\n",
      "RHE estimated sigmas are: [0.12918466], [0.13577179], [0.05269134], [0.10714339], [0.12205465], [0.13589909], [0.0659057], [0.14074607], [0.14654497]\n"
     ]
    }
   ],
   "source": [
    "sigma_list = [0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1]\n",
    "\n",
    "bin_to_snp_map = bin_to_snp(annot_matrix)\n",
    "allgen = create_allgen(bin_to_snp_map, X_imp)\n",
    "\n",
    "y, beta_list = simulator_multi_bin(allgen, sigma_list)\n",
    "\n",
    "print(f'Actual sigmas are: {sigma_list}')\n",
    "\n",
    "sigma_est=RHE_multi_bin(allgen, y, num_random_vect=10, seed=42) # run py-RHE\n",
    "print('RHE estimated sigmas are: {}'.format(\", \".join(str(s) for s in sigma_est)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv3.9",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
